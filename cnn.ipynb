{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DECAY = 0.0\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 10\n",
    "CRITERION = F.nll_loss\n",
    "EPOCHS = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, y: int, z: int, output: int):\n",
    "        super(CNN, self).__init__() \n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.conv1 = nn.Conv2d(z, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        x = torch.randn(z, y, y).view(-1, z, y, y)\n",
    "        self.to_linear = None\n",
    "        self.convs(x)\n",
    "        self.fc1 = nn.Linear(self.to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, output)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        if x.shape[2] > 1 and x.shape[3] > 1:\n",
    "            x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        if self.to_linear is None:\n",
    "            self.to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (0, 0, 0, 0))\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self.to_linear)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"./347data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"./347data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "validation_set_size = int(len(train) * 0.1)\n",
    "training_set_size = len(train) - validation_set_size\n",
    "train_set, validation_set = torch.utils.data.random_split(train, [training_set_size, validation_set_size])\n",
    "train_set = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_set = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_net = CNN(28, 1, 10).to(device)\n",
    "optimizer = optim.Adam(MNIST_net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "for batch in range(EPOCHS):\n",
    "    for data in tqdm(train_set):\n",
    "        X, y = data\n",
    "        MNIST_net.zero_grad()\n",
    "        output = MNIST_net(X.to(device))\n",
    "        loss = CRITERION(output, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9845\n",
      "Validation F1 Score: 0.9845070912248806\n",
      "Validation AUC Score: 0.9914172027862561\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "true = []\n",
    "MNIST_net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in validation_set:\n",
    "        X, y = data\n",
    "        for i in MNIST_net(X.to(device)):\n",
    "            output.append(torch.argmax(i).cpu())\n",
    "        for i in y:\n",
    "            true.append(i)\n",
    "MNIST_net.train()\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(true, output))\n",
    "print(\"Validation F1 Score:\", metrics.f1_score(true, output, average=\"macro\"))\n",
    "true = np.eye(10)[true]\n",
    "output = np.eye(10)[output]\n",
    "print(\"Validation AUC Score:\", metrics.roc_auc_score(true, output, multi_class=\"ovo\", average=\"macro\"))\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e7ff441f8c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./347data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./347data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_set_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_set_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalidation_set_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fine_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to HWC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = datasets.CIFAR10(\"./347data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.CIFAR10(\"./347data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "print(train[0][0].shape)\n",
    "validation_set_size = int(len(train) * 0.1)\n",
    "training_set_size = len(train) - validation_set_size\n",
    "train_set, validation_set = torch.utils.data.random_split(train, [training_set_size, validation_set_size])\n",
    "train_set = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_set = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:31<00:00, 158.24it/s]\n",
      "  0%|          | 15/5000 [00:00<00:35, 141.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6725, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:30<00:00, 165.40it/s]\n",
      "  0%|          | 16/5000 [00:00<00:31, 156.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9463, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:31<00:00, 159.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9590, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_net = CNN(32, 3, 10).to(device)\n",
    "optimizer = optim.Adam(CIFAR10_net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "for batch in range(EPOCHS):\n",
    "    for data in tqdm(train_set):\n",
    "        X, y = data\n",
    "        CIFAR10_net.zero_grad()\n",
    "        output = CIFAR10_net(X.to(device))\n",
    "        loss = CRITERION(output, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6664\n",
      "Validation F1 Score: 0.6557049535746451\n",
      "Validation AUC Score: 0.815043988147967\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "true = []\n",
    "CIFAR10_net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in validation_set:\n",
    "        X, y = data\n",
    "        for i in CIFAR10_net(X.to(device)):\n",
    "            output.append(torch.argmax(i).cpu())\n",
    "        for i in y:\n",
    "            true.append(i)\n",
    "CIFAR10_net.train()\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(true, output))\n",
    "print(\"Validation F1 Score:\", metrics.f1_score(true, output, average=\"macro\"))\n",
    "true = np.eye(10)[true]\n",
    "output = np.eye(10)[output]\n",
    "print(\"Validation AUC Score:\", metrics.roc_auc_score(true, output, multi_class=\"ovo\", average=\"macro\"))\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 46 51\n",
      "torch.Size([420, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "iyer = np.loadtxt(open(\"347data/iyer.txt\", \"rb\"), delimiter=\"\\t\")\n",
    "features = iyer[:, 2:].astype(float)\n",
    "labels = iyer[:, 1].astype(int)\n",
    "\n",
    "data = [] #data0\n",
    "for i in range(features.shape[0]):\n",
    "    stack = np.array([])\n",
    "    stack = np.column_stack([np.roll(features[i,], j, axis=0) for j in range(features.shape[1])]).astype(np.float32)\n",
    "    data.append([stack, np.array(labels[i] + 1, dtype=int)])\n",
    "\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "X = torch.tensor(np.array([i[0] for i in data])).view(-1, 1, 12, 12)\n",
    "y = torch.tensor(np.array([i[1] for i in data]))\n",
    "\n",
    "test_set_size = int(X.shape[0] * 0.1)\n",
    "training_set_size = X.shape[0] - test_set_size\n",
    "validation_set_size = int(training_set_size * 0.1)\n",
    "training_set_size -= validation_set_size\n",
    "print(training_set_size, validation_set_size, test_set_size)\n",
    "train_X = X[:training_set_size]\n",
    "print(train_X.shape)\n",
    "train_y = y[:training_set_size]\n",
    "validation_X = X[training_set_size:training_set_size + validation_set_size]\n",
    "validation_y = y[training_set_size:training_set_size + validation_set_size]\n",
    "test_X = X[training_set_size + validation_set_size:]\n",
    "test_y = y[training_set_size + validation_set_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:00<00:07,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4536, -2.5824, -2.4665, -2.5453, -2.5097, -2.4186, -2.5284, -2.4805,\n",
      "         -2.4965, -2.4658, -2.4399, -2.4445],\n",
      "        [-2.4322, -2.5026, -2.5133, -2.5691, -2.4722, -2.5082, -2.5298, -2.5141,\n",
      "         -2.4829, -2.4897, -2.3864, -2.4320],\n",
      "        [-2.3922, -2.4655, -2.5493, -2.6359, -2.5715, -2.4023, -2.5976, -2.5111,\n",
      "         -2.4809, -2.4460, -2.4128, -2.3928],\n",
      "        [-2.4215, -2.4393, -2.4785, -2.5370, -2.4982, -2.5083, -2.5847, -2.5334,\n",
      "         -2.4663, -2.4057, -2.4032, -2.5634],\n",
      "        [-2.4735, -2.5136, -2.5017, -2.5335, -2.4588, -2.4591, -2.5187, -2.4947,\n",
      "         -2.5052, -2.4486, -2.4374, -2.4792],\n",
      "        [-2.2489, -2.4547, -2.8261, -2.4858, -2.4436, -2.4134, -2.7700, -2.5208,\n",
      "         -2.5967, -2.3655, -2.3935, -2.4425],\n",
      "        [-1.9859, -2.4564, -2.5754, -2.5413, -2.5480, -2.4266, -2.8398, -2.6723,\n",
      "         -2.7104, -2.4417, -2.3437, -2.5443],\n",
      "        [-2.4308, -2.5143, -2.4944, -2.5447, -2.4592, -2.4555, -2.5282, -2.4900,\n",
      "         -2.5057, -2.4434, -2.4622, -2.4972],\n",
      "        [-2.4311, -2.4428, -2.5569, -2.5491, -2.4566, -2.4531, -2.5272, -2.4914,\n",
      "         -2.5394, -2.4365, -2.4360, -2.5118],\n",
      "        [-2.4521, -2.5447, -2.4895, -2.5694, -2.4484, -2.4530, -2.5620, -2.4762,\n",
      "         -2.4995, -2.4765, -2.3992, -2.4624]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:00<00:08,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4878, -2.5922, -2.5439, -2.4807, -2.4775, -2.4495, -2.6142, -2.5497,\n",
      "         -2.6442, -2.4316, -2.3173, -2.2956],\n",
      "        [-2.3102, -2.4775, -2.5230, -2.5057, -2.4903, -2.5295, -2.8761, -2.4760,\n",
      "         -2.6313, -2.6747, -2.2636, -2.2344],\n",
      "        [-2.4942, -2.5604, -2.5586, -2.4989, -2.4139, -2.4947, -2.6066, -2.4789,\n",
      "         -2.5651, -2.4927, -2.3424, -2.3511],\n",
      "        [-2.4975, -2.5334, -2.4835, -2.4907, -2.4412, -2.4858, -2.5878, -2.4698,\n",
      "         -2.5139, -2.4536, -2.4502, -2.4224],\n",
      "        [-2.4643, -2.5950, -2.5561, -2.5336, -2.4291, -2.4995, -2.6237, -2.3634,\n",
      "         -2.5223, -2.5334, -2.3757, -2.3664],\n",
      "        [-2.5025, -2.5345, -2.5133, -2.5062, -2.4042, -2.4979, -2.6084, -2.4619,\n",
      "         -2.5644, -2.4702, -2.3901, -2.3907],\n",
      "        [-2.5015, -2.5881, -2.5179, -2.5211, -2.4217, -2.4588, -2.5785, -2.4796,\n",
      "         -2.5608, -2.4861, -2.3599, -2.3751],\n",
      "        [-2.4844, -2.6443, -2.5829, -2.4167, -2.3463, -2.5431, -2.7267, -2.4225,\n",
      "         -2.6808, -2.4403, -2.3347, -2.3041],\n",
      "        [-2.4761, -2.5191, -2.5389, -2.5055, -2.4513, -2.4869, -2.6196, -2.4292,\n",
      "         -2.5251, -2.5214, -2.3678, -2.4030],\n",
      "        [-2.4623, -2.7874, -2.8325, -2.5136, -2.0888, -2.6175, -2.9918, -2.7616,\n",
      "         -2.5927, -2.5377, -2.3150, -1.8938]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.5656, -2.6070, -2.5173, -2.4350, -2.4146, -2.4380, -2.6763, -2.4296,\n",
      "         -2.5694, -2.5669, -2.3248, -2.3403],\n",
      "        [-2.5225, -2.5759, -2.5554, -2.4869, -2.4277, -2.4191, -2.6269, -2.3693,\n",
      "         -2.5648, -2.5272, -2.3744, -2.4096],\n",
      "        [-2.5055, -2.6087, -2.5434, -2.4603, -2.4534, -2.4459, -2.6397, -2.4010,\n",
      "         -2.5596, -2.5000, -2.3561, -2.3875],\n",
      "        [-2.5165, -2.6314, -2.4768, -2.4532, -2.4217, -2.4536, -2.6634, -2.3815,\n",
      "         -2.5354, -2.5511, -2.3719, -2.4097],\n",
      "        [-2.5203, -2.6580, -2.5292, -2.4734, -2.3880, -2.3850, -2.6633, -2.4218,\n",
      "         -2.5797, -2.5186, -2.3714, -2.3713],\n",
      "        [-2.6051, -2.7928, -2.6471, -2.5174, -2.3058, -2.3793, -2.8609, -2.3632,\n",
      "         -2.6642, -2.6116, -2.2007, -2.1551],\n",
      "        [-2.4757, -2.5697, -2.5527, -2.4961, -2.4249, -2.4431, -2.6175, -2.3914,\n",
      "         -2.5439, -2.5565, -2.3845, -2.3976],\n",
      "        [-2.5390, -2.6012, -2.5684, -2.4505, -2.4232, -2.4109, -2.6693, -2.3934,\n",
      "         -2.5724, -2.5636, -2.3364, -2.3548],\n",
      "        [-2.5233, -2.5829, -2.5070, -2.4560, -2.3929, -2.4761, -2.6384, -2.3863,\n",
      "         -2.5452, -2.5369, -2.4013, -2.4091],\n",
      "        [-2.5440, -2.5794, -2.4746, -2.4858, -2.4202, -2.4135, -2.6342, -2.4014,\n",
      "         -2.5418, -2.5728, -2.3952, -2.3949]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.5670, -2.6418, -2.4632, -2.4112, -2.4029, -2.4813, -2.6305, -2.3536,\n",
      "         -2.6191, -2.5809, -2.3965, -2.3396],\n",
      "        [-2.5157, -2.6322, -2.5233, -2.4166, -2.3770, -2.4042, -2.6815, -2.3424,\n",
      "         -2.5638, -2.5620, -2.4138, -2.4476],\n",
      "        [-2.4994, -2.5858, -2.4845, -2.4466, -2.4155, -2.4273, -2.6345, -2.3759,\n",
      "         -2.5697, -2.6124, -2.3953, -2.4166],\n",
      "        [-2.6256, -2.7590, -2.6609, -2.3678, -2.3062, -2.3458, -2.7818, -2.2624,\n",
      "         -2.7578, -2.6639, -2.3439, -2.2056],\n",
      "        [-2.5232, -2.6611, -2.5138, -2.3924, -2.3959, -2.4425, -2.6641, -2.3504,\n",
      "         -2.5888, -2.5978, -2.3991, -2.3624],\n",
      "        [-2.5178, -2.6252, -2.4788, -2.4675, -2.4318, -2.4345, -2.6122, -2.3795,\n",
      "         -2.6539, -2.5232, -2.3711, -2.3768],\n",
      "        [-2.5293, -2.5966, -2.4868, -2.4253, -2.4362, -2.4183, -2.6491, -2.3966,\n",
      "         -2.5529, -2.6105, -2.3845, -2.3824],\n",
      "        [-2.5661, -2.7470, -2.6077, -2.4155, -2.4097, -2.4242, -2.6102, -2.4275,\n",
      "         -2.7510, -2.6534, -2.3261, -2.0883],\n",
      "        [-2.5311, -2.6135, -2.4664, -2.4689, -2.4030, -2.4125, -2.6424, -2.3626,\n",
      "         -2.5599, -2.5640, -2.4049, -2.4350],\n",
      "        [-2.5782, -2.6074, -2.5452, -2.4748, -2.4026, -2.3946, -2.6890, -2.3279,\n",
      "         -2.6757, -2.5848, -2.2811, -2.3630]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.5213, -2.6370, -2.4811, -2.3080, -2.3892, -2.4423, -2.6805, -2.3691,\n",
      "         -2.6321, -2.5665, -2.4345, -2.4323],\n",
      "        [-2.5658, -2.6150, -2.4564, -2.3330, -2.4082, -2.4082, -2.6690, -2.3795,\n",
      "         -2.6157, -2.6141, -2.4127, -2.4144],\n",
      "        [-2.5198, -2.6463, -2.4612, -2.3713, -2.4069, -2.3955, -2.6607, -2.3730,\n",
      "         -2.5994, -2.5768, -2.4280, -2.4412],\n",
      "        [-2.4603, -2.7084, -2.5984, -2.2497, -2.4466, -2.4418, -2.8013, -2.1463,\n",
      "         -2.8375, -2.7425, -2.2653, -2.4068],\n",
      "        [-2.5057, -2.6194, -2.4727, -2.4155, -2.4145, -2.4336, -2.6558, -2.3763,\n",
      "         -2.6156, -2.6005, -2.3561, -2.4142],\n",
      "        [-2.8833, -3.1429, -2.7873, -2.1640, -2.1719, -2.3596, -3.0040, -2.1365,\n",
      "         -3.1992, -2.8711, -2.1469, -2.0093],\n",
      "        [-2.5198, -2.5861, -2.5040, -2.3976, -2.3979, -2.4539, -2.6715, -2.3490,\n",
      "         -2.5947, -2.5609, -2.3945, -2.4428],\n",
      "        [-2.5130, -2.6125, -2.4231, -2.3860, -2.4692, -2.4196, -2.6442, -2.3662,\n",
      "         -2.6276, -2.5822, -2.3901, -2.4419],\n",
      "        [-2.6922, -2.7990, -2.5053, -2.2191, -2.4580, -2.4590, -2.8064, -2.1854,\n",
      "         -2.8871, -2.6654, -2.2639, -2.2274],\n",
      "        [-2.5477, -2.6299, -2.5556, -2.3167, -2.3901, -2.4152, -2.6482, -2.3729,\n",
      "         -2.6932, -2.6589, -2.3397, -2.3602]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [00:00<00:05,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5862, -2.6871, -2.4516, -2.3079, -2.4416, -2.3895, -2.7013, -2.3140,\n",
      "         -2.6830, -2.5504, -2.3938, -2.4234],\n",
      "        [-2.5462, -2.7149, -2.4397, -2.2925, -2.4444, -2.3763, -2.6862, -2.3038,\n",
      "         -2.7506, -2.5752, -2.4061, -2.4157],\n",
      "        [-2.5387, -2.6456, -2.4601, -2.2925, -2.4272, -2.4156, -2.6647, -2.3530,\n",
      "         -2.6214, -2.6044, -2.4438, -2.4319],\n",
      "        [-2.5470, -2.7272, -2.4321, -2.2335, -2.4753, -2.3655, -2.8038, -2.3327,\n",
      "         -2.5753, -2.6425, -2.4279, -2.4070],\n",
      "        [-2.5517, -2.6318, -2.4761, -2.3461, -2.4244, -2.3847, -2.6622, -2.3630,\n",
      "         -2.6633, -2.5337, -2.4495, -2.4048],\n",
      "        [-2.5175, -2.6613, -2.4577, -2.2537, -2.4410, -2.4317, -2.6973, -2.3336,\n",
      "         -2.6564, -2.6075, -2.4205, -2.4448],\n",
      "        [-2.5327, -2.7077, -2.4281, -2.2816, -2.4710, -2.3801, -2.6836, -2.3535,\n",
      "         -2.6615, -2.6046, -2.4295, -2.3936],\n",
      "        [-2.6007, -2.8859, -2.6171, -2.1197, -2.3814, -2.2695, -2.7578, -2.3218,\n",
      "         -2.8914, -2.6909, -2.2889, -2.3550],\n",
      "        [-2.5394, -2.6518, -2.4473, -2.2680, -2.4544, -2.4322, -2.6626, -2.3605,\n",
      "         -2.6865, -2.6092, -2.4142, -2.3917],\n",
      "        [-2.5501, -2.6451, -2.4275, -2.3326, -2.4177, -2.4418, -2.6378, -2.3530,\n",
      "         -2.6559, -2.5676, -2.4275, -2.4340]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6000, -2.7192, -2.4244, -2.1862, -2.4340, -2.4486, -2.6709, -2.3401,\n",
      "         -2.6782, -2.6294, -2.4183, -2.4142],\n",
      "        [-2.6488, -2.7015, -2.4353, -2.1644, -2.4502, -2.4461, -2.7115, -2.3147,\n",
      "         -2.7370, -2.6096, -2.3995, -2.3801],\n",
      "        [-2.5205, -3.0197, -2.5103, -2.0217, -2.5275, -2.3792, -2.9262, -2.2326,\n",
      "         -2.9194, -2.8342, -2.2743, -2.2242],\n",
      "        [-2.7904, -3.1168, -2.5460, -1.9939, -2.4668, -2.4808, -2.9635, -2.0458,\n",
      "         -3.1567, -2.8792, -2.2139, -2.1014],\n",
      "        [-2.5629, -2.7446, -2.4401, -2.2406, -2.4878, -2.4164, -2.6958, -2.2649,\n",
      "         -2.7134, -2.6284, -2.4073, -2.3765],\n",
      "        [-2.5167, -2.6741, -2.4022, -2.2217, -2.4510, -2.4537, -2.7606, -2.3341,\n",
      "         -2.7101, -2.5747, -2.4236, -2.4336],\n",
      "        [-2.6698, -3.0924, -2.4769, -1.8939, -2.6022, -2.3357, -3.0155, -2.1152,\n",
      "         -3.1970, -2.9165, -2.1987, -2.2593],\n",
      "        [-2.5607, -2.7301, -2.3772, -2.1902, -2.4899, -2.4229, -2.6986, -2.3646,\n",
      "         -2.6641, -2.6208, -2.4496, -2.3944],\n",
      "        [-2.5686, -2.7303, -2.4526, -2.1884, -2.4644, -2.4280, -2.7025, -2.3295,\n",
      "         -2.7512, -2.5352, -2.3931, -2.4316],\n",
      "        [-2.5116, -2.6756, -2.4175, -2.2478, -2.4395, -2.3995, -2.6811, -2.3452,\n",
      "         -2.6897, -2.6081, -2.4503, -2.4640]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [00:01<00:02,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7677, -3.1375, -2.5170, -1.8865, -2.5354, -2.3605, -2.9968, -2.1558,\n",
      "         -2.9179, -2.7867, -2.4036, -2.1535],\n",
      "        [-2.7590, -3.4756, -2.5300, -1.5044, -2.6348, -2.4770, -3.1377, -2.0996,\n",
      "         -3.4796, -3.0416, -2.3014, -2.2674],\n",
      "        [-2.7807, -3.1517, -2.5495, -1.6543, -2.6740, -2.3233, -3.1303, -2.1174,\n",
      "         -3.1277, -3.0625, -2.3174, -2.2463],\n",
      "        [-2.6219, -2.7647, -2.3775, -2.1203, -2.4770, -2.4110, -2.7293, -2.3472,\n",
      "         -2.7169, -2.6331, -2.4313, -2.3959],\n",
      "        [-2.5898, -2.6861, -2.3708, -2.1788, -2.4429, -2.4511, -2.6742, -2.3515,\n",
      "         -2.7423, -2.6219, -2.4200, -2.4426],\n",
      "        [-2.6585, -3.4738, -2.5459, -1.4879, -2.6967, -2.5693, -3.0633, -2.1835,\n",
      "         -3.2167, -3.0574, -2.5914, -2.0458],\n",
      "        [-2.7230, -3.0699, -2.4341, -1.8189, -2.5110, -2.3606, -2.8867, -2.3131,\n",
      "         -2.9562, -2.6863, -2.4291, -2.3077],\n",
      "        [-2.5944, -2.7847, -2.3475, -2.1298, -2.4725, -2.4573, -2.7019, -2.3404,\n",
      "         -2.7468, -2.6110, -2.4381, -2.3995],\n",
      "        [-2.5588, -2.7351, -2.3794, -2.1423, -2.4948, -2.4427, -2.7319, -2.3273,\n",
      "         -2.7155, -2.6232, -2.4292, -2.4216],\n",
      "        [-2.5649, -2.7693, -2.3551, -2.1529, -2.4656, -2.4161, -2.7253, -2.3904,\n",
      "         -2.6579, -2.5874, -2.5140, -2.3888]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6692, -3.3822, -2.5440, -1.4226, -2.8211, -2.4197, -3.5927, -2.1188,\n",
      "         -3.3403, -3.1122, -2.3174, -2.2786],\n",
      "        [-2.6623, -3.0529, -2.3097, -1.6943, -2.6387, -2.4387, -2.8976, -2.3969,\n",
      "         -2.9429, -2.6118, -2.5241, -2.4207],\n",
      "        [-2.7065, -2.9318, -2.3324, -1.9917, -2.5344, -2.4039, -2.8408, -2.2414,\n",
      "         -2.8249, -2.5934, -2.4997, -2.3449],\n",
      "        [-2.5763, -2.9880, -2.2867, -1.8844, -2.6566, -2.4170, -3.0177, -2.2801,\n",
      "         -2.9501, -2.6396, -2.4442, -2.3131],\n",
      "        [-2.5950, -2.7809, -2.3307, -2.0875, -2.4530, -2.4150, -2.7569, -2.3399,\n",
      "         -2.7477, -2.6182, -2.4940, -2.4382],\n",
      "        [-2.7686, -3.2512, -2.3830, -1.6834, -2.6422, -2.3104, -2.9974, -2.2408,\n",
      "         -3.0817, -2.7334, -2.4318, -2.3535],\n",
      "        [-2.5807, -2.7162, -2.3258, -2.0975, -2.5025, -2.4348, -2.7089, -2.3799,\n",
      "         -2.7867, -2.5957, -2.4929, -2.4067],\n",
      "        [-2.6748, -3.0925, -2.3351, -1.7779, -2.5191, -2.4589, -2.9711, -2.1987,\n",
      "         -2.9854, -2.6930, -2.4641, -2.4262],\n",
      "        [-2.5780, -2.7824, -2.3214, -2.1557, -2.5051, -2.4278, -2.6921, -2.3232,\n",
      "         -2.6407, -2.6084, -2.5052, -2.4533],\n",
      "        [-2.6055, -2.8251, -2.3259, -2.0501, -2.5146, -2.4297, -2.7708, -2.2978,\n",
      "         -2.8131, -2.5959, -2.4705, -2.4166]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.7101, -2.9500, -2.2531, -1.9941, -2.5522, -2.3586, -2.8363, -2.3419,\n",
      "         -2.7408, -2.5652, -2.5475, -2.3753],\n",
      "        [-2.6941, -2.8902, -2.2586, -1.9758, -2.5424, -2.3989, -2.7778, -2.3419,\n",
      "         -2.7857, -2.5601, -2.5481, -2.4230],\n",
      "        [-2.5855, -2.8529, -2.2980, -2.0438, -2.5235, -2.4604, -2.7833, -2.3119,\n",
      "         -2.7644, -2.5761, -2.5211, -2.3966],\n",
      "        [-2.5836, -3.0552, -2.2281, -1.8678, -2.6448, -2.4807, -2.9099, -2.3258,\n",
      "         -2.9035, -2.5461, -2.4326, -2.4388],\n",
      "        [-2.8167, -3.2157, -2.1104, -1.6421, -2.7610, -2.4834, -3.2298, -2.2062,\n",
      "         -3.1171, -2.5857, -2.5630, -2.3835],\n",
      "        [-2.7167, -2.9116, -2.2741, -1.9721, -2.6290, -2.3472, -2.7697, -2.3624,\n",
      "         -2.7428, -2.5629, -2.5422, -2.3790],\n",
      "        [-2.8179, -3.4668, -2.3143, -1.6650, -2.7556, -2.3006, -3.0593, -2.2925,\n",
      "         -3.1425, -2.5448, -2.5236, -2.2304],\n",
      "        [-2.6583, -2.9011, -2.2566, -1.9435, -2.5368, -2.4214, -2.7544, -2.3720,\n",
      "         -2.8104, -2.5479, -2.5390, -2.4670],\n",
      "        [-2.6656, -2.8286, -2.2720, -2.0761, -2.5197, -2.4339, -2.7541, -2.3494,\n",
      "         -2.7492, -2.5610, -2.4719, -2.4088],\n",
      "        [-2.6026, -2.8675, -2.2447, -2.1000, -2.5542, -2.4447, -2.7879, -2.2993,\n",
      "         -2.7137, -2.5211, -2.5352, -2.4263]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6677, -2.9558, -2.2165, -1.8902, -2.5683, -2.4740, -2.8293, -2.4025,\n",
      "         -2.8190, -2.4708, -2.6224, -2.3942],\n",
      "        [-2.5778, -2.8667, -2.3201, -2.0657, -2.5501, -2.3745, -2.8206, -2.3632,\n",
      "         -2.6701, -2.4691, -2.5889, -2.4265],\n",
      "        [-2.6895, -3.1551, -2.2904, -1.8038, -2.7442, -2.3987, -3.0443, -2.2463,\n",
      "         -3.1006, -2.5149, -2.4625, -2.2645],\n",
      "        [-2.9662, -3.2142, -2.1924, -1.7837, -2.7856, -2.4738, -3.1590, -2.2174,\n",
      "         -3.0605, -2.2992, -2.4632, -2.3129],\n",
      "        [-2.9795, -3.9067, -2.3166, -1.2203, -3.2704, -2.4558, -3.6174, -2.2318,\n",
      "         -3.6369, -2.6086, -2.7542, -2.1739],\n",
      "        [-2.7513, -3.1184, -2.2944, -1.7357, -2.6709, -2.4271, -2.9783, -2.3218,\n",
      "         -2.8729, -2.5262, -2.5638, -2.3554],\n",
      "        [-2.6103, -2.9267, -2.2681, -1.9982, -2.5948, -2.4293, -2.7914, -2.3322,\n",
      "         -2.7244, -2.5437, -2.5248, -2.4257],\n",
      "        [-2.6610, -2.9782, -2.1847, -1.9971, -2.5774, -2.4522, -2.8448, -2.3290,\n",
      "         -2.8183, -2.4830, -2.5836, -2.3574],\n",
      "        [-2.6119, -2.8401, -2.2450, -2.0817, -2.5618, -2.4147, -2.7927, -2.3685,\n",
      "         -2.6861, -2.5275, -2.5430, -2.4138],\n",
      "        [-2.6222, -2.8862, -2.2335, -2.0242, -2.5725, -2.4437, -2.8315, -2.2895,\n",
      "         -2.7004, -2.5686, -2.5696, -2.4249]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-3.1020, -3.9885, -2.2521, -1.2079, -3.0411, -2.3509, -3.6436, -2.2939,\n",
      "         -3.3844, -2.4371, -2.9805, -2.4045],\n",
      "        [-2.6450, -3.0492, -2.2024, -1.9201, -2.6127, -2.4445, -2.9219, -2.3353,\n",
      "         -2.7918, -2.4160, -2.5933, -2.4261],\n",
      "        [-2.7121, -3.0392, -2.1616, -1.8886, -2.6180, -2.4363, -2.8865, -2.3562,\n",
      "         -2.7732, -2.4824, -2.6244, -2.4097],\n",
      "        [-2.6803, -3.0269, -2.1579, -1.9539, -2.5901, -2.4040, -2.9027, -2.3331,\n",
      "         -2.7340, -2.4618, -2.6443, -2.4398],\n",
      "        [-2.6240, -2.9303, -2.2983, -1.9205, -2.5431, -2.4595, -2.8540, -2.3541,\n",
      "         -2.7195, -2.4916, -2.6106, -2.4273],\n",
      "        [-2.6825, -3.0127, -2.1090, -1.8882, -2.6369, -2.4778, -2.8774, -2.3780,\n",
      "         -2.8402, -2.4329, -2.6102, -2.4592],\n",
      "        [-2.6153, -2.9345, -2.2422, -1.9943, -2.6161, -2.4017, -2.8918, -2.3256,\n",
      "         -2.7068, -2.4552, -2.5862, -2.4464],\n",
      "        [-2.8387, -3.1270, -2.1760, -1.7550, -2.6718, -2.5105, -2.9678, -2.2647,\n",
      "         -2.9630, -2.4888, -2.5603, -2.3681],\n",
      "        [-2.6703, -2.9285, -2.2035, -1.9562, -2.6099, -2.4805, -2.8747, -2.3176,\n",
      "         -2.7743, -2.4030, -2.5847, -2.4646],\n",
      "        [-2.6944, -2.9479, -2.1589, -1.9453, -2.6186, -2.4413, -2.8539, -2.4097,\n",
      "         -2.6842, -2.4375, -2.6207, -2.4564]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6777, -3.0762, -2.1498, -1.8474, -2.6577, -2.4086, -2.9115, -2.3674,\n",
      "         -2.8503, -2.3911, -2.6508, -2.4904],\n",
      "        [-2.6199, -3.0430, -2.1714, -1.9441, -2.6350, -2.3992, -2.9178, -2.3841,\n",
      "         -2.7819, -2.4421, -2.5613, -2.4358],\n",
      "        [-3.0361, -3.9081, -2.1566, -1.2861, -3.0046, -2.5793, -3.2621, -2.3292,\n",
      "         -3.2876, -2.2234, -2.8761, -2.5662],\n",
      "        [-2.6261, -2.9987, -2.1977, -1.9040, -2.5788, -2.4664, -2.8652, -2.3705,\n",
      "         -2.7055, -2.5468, -2.5900, -2.4486],\n",
      "        [-2.6880, -3.1029, -2.1738, -1.8792, -2.6619, -2.3889, -2.8974, -2.3707,\n",
      "         -2.7861, -2.3763, -2.6242, -2.4837],\n",
      "        [-2.9462, -3.6854, -2.0552, -1.5118, -2.9169, -2.3507, -3.2825, -2.3354,\n",
      "         -3.1248, -2.3651, -2.8847, -2.3400],\n",
      "        [-2.8468, -3.4394, -2.2275, -1.5408, -2.6646, -2.4905, -3.2087, -2.3477,\n",
      "         -2.9807, -2.2934, -2.7274, -2.4972],\n",
      "        [-2.6614, -2.9911, -2.2149, -1.9033, -2.5760, -2.4389, -2.8642, -2.4353,\n",
      "         -2.7196, -2.4430, -2.6616, -2.3958],\n",
      "        [-2.6439, -2.9971, -2.1171, -1.9280, -2.7175, -2.4361, -2.9032, -2.4240,\n",
      "         -2.7168, -2.4437, -2.6182, -2.4039],\n",
      "        [-2.6939, -3.0828, -2.2036, -1.8256, -2.6639, -2.4265, -2.9161, -2.3658,\n",
      "         -2.7937, -2.3826, -2.6757, -2.4462]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.7714, -3.4285, -2.0800, -1.6127, -2.9013, -2.5127, -3.1587, -2.3936,\n",
      "         -2.9379, -2.2414, -2.8630, -2.3588],\n",
      "        [-2.8131, -3.1863, -2.1563, -1.8256, -2.6387, -2.3582, -2.9760, -2.3591,\n",
      "         -2.7261, -2.3318, -2.7184, -2.5051],\n",
      "        [-2.7359, -3.0247, -2.1630, -1.8498, -2.6355, -2.4646, -2.9206, -2.3953,\n",
      "         -2.7911, -2.3561, -2.6395, -2.4649],\n",
      "        [-2.7052, -3.0637, -2.1553, -1.8233, -2.6142, -2.4292, -2.8880, -2.4279,\n",
      "         -2.7704, -2.4314, -2.6663, -2.4797],\n",
      "        [-2.7170, -3.1720, -2.2311, -1.7554, -2.7012, -2.3928, -3.0136, -2.4298,\n",
      "         -2.8503, -2.2910, -2.7287, -2.3882],\n",
      "        [-3.6775, -4.6072, -2.2361, -1.0975, -3.3302, -2.6192, -3.7713, -2.1968,\n",
      "         -3.5266, -2.2878, -3.0288, -2.2824],\n",
      "        [-2.6228, -3.0129, -2.1195, -1.9024, -2.6440, -2.3946, -2.9309, -2.3890,\n",
      "         -2.6578, -2.4993, -2.7203, -2.4831],\n",
      "        [-2.6426, -3.0773, -2.2273, -1.9182, -2.6180, -2.4287, -2.9542, -2.3290,\n",
      "         -2.6831, -2.3707, -2.6690, -2.4495],\n",
      "        [-3.6614, -5.2801, -2.4543, -0.6898, -4.1722, -2.6832, -4.7722, -2.4288,\n",
      "         -3.9948, -2.3384, -3.5809, -2.8385],\n",
      "        [-2.5842, -3.1311, -2.1529, -1.8935, -2.6230, -2.4398, -2.9406, -2.3859,\n",
      "         -2.7702, -2.3973, -2.6343, -2.4746]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.8104, -3.2874, -2.1206, -1.6647, -2.7795, -2.4018, -3.0483, -2.4153,\n",
      "         -2.9186, -2.2407, -2.8162, -2.4814],\n",
      "        [-2.6949, -3.1970, -2.0722, -1.7270, -2.6855, -2.4703, -3.0548, -2.4439,\n",
      "         -2.8173, -2.2821, -2.7511, -2.5842],\n",
      "        [-2.6025, -3.0979, -2.1207, -1.7898, -2.7048, -2.4165, -3.0107, -2.4148,\n",
      "         -2.7670, -2.3859, -2.7263, -2.5414],\n",
      "        [-5.0803, -8.1798, -3.0383, -0.2825, -6.0272, -3.9854, -6.6408, -3.2726,\n",
      "         -6.1124, -2.3216, -5.9182, -3.5589],\n",
      "        [-2.6411, -3.1937, -2.0578, -1.7987, -2.6575, -2.4458, -2.9310, -2.5220,\n",
      "         -2.7575, -2.3469, -2.7631, -2.5034],\n",
      "        [-4.0887, -6.1943, -2.4096, -0.7496, -3.9685, -2.5627, -5.1166, -2.4648,\n",
      "         -4.2430, -1.9815, -4.0583, -2.7764],\n",
      "        [-2.9308, -3.8375, -2.0587, -1.2712, -3.1056, -2.5612, -3.5356, -2.4955,\n",
      "         -3.2188, -2.1751, -3.0228, -2.5117],\n",
      "        [-2.6510, -3.0823, -2.1316, -1.8002, -2.6556, -2.4980, -2.9451, -2.4003,\n",
      "         -2.7732, -2.3605, -2.7264, -2.5062],\n",
      "        [-2.6915, -3.1127, -2.1040, -1.8526, -2.6818, -2.5070, -2.9893, -2.3605,\n",
      "         -2.7450, -2.2931, -2.7199, -2.4863],\n",
      "        [-2.6767, -3.1873, -2.0962, -1.7487, -2.6330, -2.4985, -3.0380, -2.3849,\n",
      "         -2.7761, -2.3857, -2.7546, -2.5135]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.5275, -3.2967, -2.1057, -1.6988, -2.6832, -2.4993, -3.1584, -2.3955,\n",
      "         -2.7637, -2.2750, -2.9462, -2.5773],\n",
      "        [-2.6715, -3.2456, -2.1022, -1.7808, -2.7263, -2.4235, -3.0035, -2.4283,\n",
      "         -2.8566, -2.2203, -2.7957, -2.4982],\n",
      "        [-2.6808, -3.3220, -2.0285, -1.7525, -2.7082, -2.3945, -3.0666, -2.5008,\n",
      "         -2.8620, -2.2025, -2.8600, -2.5369],\n",
      "        [-2.8285, -3.7304, -2.0668, -1.3719, -3.0457, -2.5647, -3.5324, -2.3993,\n",
      "         -3.1351, -2.1442, -3.0386, -2.4814],\n",
      "        [-2.6964, -3.0863, -2.1476, -1.8588, -2.6145, -2.4551, -2.9639, -2.4135,\n",
      "         -2.7288, -2.3329, -2.6933, -2.4758],\n",
      "        [-2.6591, -3.0870, -2.1016, -1.8382, -2.6880, -2.3729, -3.0062, -2.4295,\n",
      "         -2.7539, -2.2714, -2.8241, -2.5514],\n",
      "        [-3.5045, -4.3196, -1.9824, -1.1695, -3.4381, -2.4854, -4.0687, -2.3320,\n",
      "         -3.2976, -2.1394, -3.4815, -2.3720],\n",
      "        [-2.6138, -3.1091, -2.0818, -1.8964, -2.6336, -2.4603, -2.9526, -2.4634,\n",
      "         -2.7449, -2.2768, -2.7629, -2.4921],\n",
      "        [-3.0048, -3.8880, -2.0021, -1.4093, -3.0856, -2.5373, -3.4917, -2.2876,\n",
      "         -3.0797, -2.2062, -3.0074, -2.4265],\n",
      "        [-2.7179, -3.1815, -2.1323, -1.7026, -2.6381, -2.4222, -3.0748, -2.3875,\n",
      "         -2.8279, -2.3293, -2.8245, -2.5565]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.7243, -3.2902, -2.0644, -1.7017, -2.6695, -2.4521, -3.1339, -2.4381,\n",
      "         -2.7930, -2.2864, -2.9199, -2.4673],\n",
      "        [-2.8728, -3.7463, -1.9991, -1.4643, -2.9003, -2.4552, -3.4650, -2.3469,\n",
      "         -3.1382, -2.2640, -2.9639, -2.4482],\n",
      "        [-2.9630, -4.0754, -2.0201, -1.3516, -3.1269, -2.5878, -3.7182, -2.3592,\n",
      "         -3.0899, -2.0969, -3.1461, -2.4003],\n",
      "        [-2.6564, -3.2082, -2.0393, -1.7397, -2.7124, -2.5015, -3.0908, -2.4770,\n",
      "         -2.7704, -2.2940, -2.8580, -2.4653],\n",
      "        [-3.4050, -4.8993, -2.0585, -1.1010, -3.5106, -2.3139, -4.0633, -2.5579,\n",
      "         -3.4176, -2.1608, -3.5848, -2.3029],\n",
      "        [-2.9804, -4.0971, -2.0018, -1.3515, -3.2351, -2.4556, -3.7612, -2.4266,\n",
      "         -3.4410, -1.9689, -3.2434, -2.3944],\n",
      "        [-2.6494, -3.3340, -2.0222, -1.7160, -2.7950, -2.4322, -3.1402, -2.4229,\n",
      "         -2.8300, -2.2573, -2.8849, -2.5121],\n",
      "        [-2.7050, -3.0908, -2.0537, -1.8495, -2.5798, -2.4486, -3.0339, -2.5037,\n",
      "         -2.6717, -2.3908, -2.7004, -2.4999],\n",
      "        [-2.6702, -3.1882, -2.0390, -1.8088, -2.6394, -2.4706, -3.0382, -2.4549,\n",
      "         -2.8577, -2.2638, -2.8244, -2.4643],\n",
      "        [-2.7552, -3.8319, -1.8531, -1.4511, -3.1054, -2.5786, -3.5135, -2.5127,\n",
      "         -3.0868, -2.0561, -3.0593, -2.6361]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-3.0982, -4.7476, -2.0697, -1.1112, -3.3687, -2.3678, -4.2437, -2.4828,\n",
      "         -3.3789, -2.1026, -3.4082, -2.5838],\n",
      "        [-3.6764, -6.0911, -2.0505, -1.3008, -3.9232, -1.8762, -4.7004, -3.0343,\n",
      "         -3.5822, -1.7640, -3.9111, -2.1030],\n",
      "        [-3.2955, -4.8543, -2.0187, -1.2397, -3.5538, -2.2642, -4.3254, -2.7073,\n",
      "         -3.4402, -1.8126, -3.5655, -2.3348],\n",
      "        [-3.0950, -4.5164, -1.9638, -1.2117, -3.4138, -2.5739, -4.0957, -2.4419,\n",
      "         -3.2785, -2.0055, -3.3521, -2.4567],\n",
      "        [-2.7870, -3.7197, -1.9427, -1.4481, -3.0192, -2.4621, -3.5394, -2.4177,\n",
      "         -3.1358, -2.2082, -3.0897, -2.4686],\n",
      "        [-3.2230, -4.3630, -1.8423, -1.3592, -3.1950, -2.5645, -3.6802, -2.4738,\n",
      "         -3.3425, -2.0414, -3.1887, -2.3201],\n",
      "        [-2.9074, -3.8971, -1.9236, -1.4548, -3.0092, -2.4575, -3.5267, -2.5591,\n",
      "         -3.0920, -2.1550, -3.1577, -2.3027],\n",
      "        [-2.7672, -3.4350, -2.0096, -1.6801, -2.7595, -2.4071, -3.2449, -2.5362,\n",
      "         -2.9101, -2.2009, -2.8319, -2.4202],\n",
      "        [-3.2968, -5.2465, -2.0805, -1.1291, -3.7404, -2.6012, -4.2632, -2.6144,\n",
      "         -3.7270, -1.8867, -3.5493, -2.1207],\n",
      "        [-3.4230, -4.7413, -1.8843, -0.9903, -3.4618, -2.6856, -4.2999, -2.8762,\n",
      "         -3.7949, -2.0922, -3.8272, -2.3218]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[ -2.6869,  -3.3812,  -1.9969,  -1.7805,  -2.7127,  -2.3483,  -3.1170,\n",
      "          -2.5369,  -2.9031,  -2.2241,  -2.8982,  -2.4062],\n",
      "        [ -2.6861,  -3.4189,  -2.0482,  -1.6823,  -2.7737,  -2.4460,  -3.1919,\n",
      "          -2.4695,  -2.9661,  -2.1879,  -2.8904,  -2.4059],\n",
      "        [ -2.6738,  -3.3219,  -1.9418,  -1.7544,  -2.7166,  -2.4602,  -3.1287,\n",
      "          -2.4964,  -2.8679,  -2.2512,  -2.8946,  -2.4844],\n",
      "        [ -2.8820,  -4.4867,  -2.0497,  -1.6135,  -3.3623,  -2.0223,  -3.7583,\n",
      "          -2.4601,  -3.0787,  -2.0238,  -3.1441,  -2.2281],\n",
      "        [ -3.7408,  -6.0171,  -2.5968,  -1.1101,  -4.2988,  -1.9371,  -4.9501,\n",
      "          -2.7975,  -3.7041,  -1.6693,  -4.1757,  -2.1570],\n",
      "        [ -2.6817,  -3.9367,  -2.0384,  -1.6446,  -2.9924,  -2.1627,  -3.4686,\n",
      "          -2.5530,  -3.0542,  -2.0851,  -3.0719,  -2.3359],\n",
      "        [ -2.6793,  -3.3968,  -2.0292,  -1.7534,  -2.8014,  -2.3666,  -3.1459,\n",
      "          -2.5592,  -2.8705,  -2.1752,  -2.8491,  -2.4057],\n",
      "        [ -2.6533,  -3.2916,  -2.0307,  -1.8631,  -2.6468,  -2.3775,  -2.9975,\n",
      "          -2.4877,  -2.8281,  -2.2049,  -2.8542,  -2.4975],\n",
      "        [ -2.5627,  -3.3679,  -2.0200,  -1.8134,  -2.7798,  -2.3556,  -3.0838,\n",
      "          -2.4510,  -2.8500,  -2.2244,  -2.8864,  -2.5004],\n",
      "        [ -5.8027, -10.7512,  -2.7707,  -0.8434,  -7.4881,  -2.5425,  -8.4831,\n",
      "          -3.9508,  -6.6467,  -0.9773,  -6.8416,  -3.6223]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[ -2.6478,  -3.3459,  -2.1610,  -1.8539,  -2.7321,  -2.3309,  -3.0600,\n",
      "          -2.3943,  -2.8319,  -2.1909,  -2.7865,  -2.4151],\n",
      "        [ -3.0688,  -5.4794,  -2.2361,  -1.3815,  -4.0427,  -2.1880,  -4.5578,\n",
      "          -2.4202,  -3.6972,  -1.4729,  -3.5960,  -2.5168],\n",
      "        [ -2.6328,  -3.5750,  -2.0078,  -1.7528,  -2.8358,  -2.3745,  -3.2801,\n",
      "          -2.4887,  -2.8330,  -2.1125,  -2.9928,  -2.4053],\n",
      "        [ -2.6572,  -3.4046,  -2.0287,  -1.6951,  -2.7950,  -2.3704,  -3.1486,\n",
      "          -2.4506,  -2.8620,  -2.2372,  -2.8873,  -2.5486],\n",
      "        [ -2.7072,  -3.4056,  -2.0328,  -1.8125,  -2.7080,  -2.3951,  -3.1169,\n",
      "          -2.4884,  -2.9315,  -2.1255,  -2.8875,  -2.3828],\n",
      "        [ -2.6488,  -3.4482,  -2.0683,  -1.8235,  -2.7555,  -2.3877,  -3.1543,\n",
      "          -2.5135,  -2.8784,  -2.0524,  -2.8736,  -2.4150],\n",
      "        [ -3.3496,  -5.4104,  -2.2319,  -1.3677,  -3.6432,  -2.2230,  -4.2840,\n",
      "          -2.5112,  -3.3715,  -1.7832,  -3.7355,  -1.9471],\n",
      "        [ -2.6232,  -3.4037,  -2.0081,  -1.7590,  -2.7620,  -2.4262,  -3.1743,\n",
      "          -2.5015,  -2.7978,  -2.2308,  -2.8884,  -2.4265],\n",
      "        [ -6.8945, -15.0323,  -3.5886,  -1.7757, -10.7820,  -3.1691, -10.5669,\n",
      "          -5.5118,  -8.9624,  -0.2841,  -8.7134,  -5.8480],\n",
      "        [ -2.6254,  -3.7743,  -2.0189,  -1.6421,  -2.9963,  -2.3036,  -3.4099,\n",
      "          -2.4761,  -3.0030,  -2.1124,  -3.0867,  -2.3534]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6671, -3.5085, -2.0198, -1.7610, -2.8238, -2.4034, -3.1576, -2.4624,\n",
      "         -2.8500, -2.1005, -2.9295, -2.4670],\n",
      "        [-2.6915, -4.1842, -2.1232, -1.6813, -3.2964, -2.3028, -3.5414, -2.4954,\n",
      "         -2.9948, -1.6768, -3.1629, -2.4833],\n",
      "        [-2.5515, -3.4260, -2.1252, -1.8674, -2.7402, -2.3856, -3.1050, -2.4920,\n",
      "         -2.7358, -2.1124, -2.8994, -2.4014],\n",
      "        [-2.6599, -3.4136, -2.0536, -1.8183, -2.8524, -2.3407, -3.2142, -2.4451,\n",
      "         -2.8613, -2.1120, -2.8848, -2.3900],\n",
      "        [-2.5313, -3.3847, -2.0645, -1.7969, -2.7296, -2.4409, -3.1862, -2.4726,\n",
      "         -2.8318, -2.2056, -2.8907, -2.3947],\n",
      "        [-2.5268, -3.3868, -2.0935, -1.8181, -2.6911, -2.4263, -3.1019, -2.4992,\n",
      "         -2.7616, -2.1944, -2.8301, -2.4796],\n",
      "        [-2.7743, -3.9488, -2.1291, -1.7204, -2.9855, -2.1758, -3.4333, -2.6235,\n",
      "         -3.0324, -1.8287, -3.1485, -2.3045],\n",
      "        [-2.8113, -4.0690, -2.0947, -1.8018, -2.9780, -2.0983, -3.4701, -2.5616,\n",
      "         -2.9024, -1.8542, -3.1426, -2.3209],\n",
      "        [-2.7201, -4.0698, -2.1671, -1.6164, -3.1924, -2.2876, -3.5099, -2.2988,\n",
      "         -2.9742, -1.9481, -3.1025, -2.3806],\n",
      "        [-2.7051, -4.1412, -2.1891, -1.6439, -3.1608, -2.3785, -3.4462, -2.5123,\n",
      "         -2.9576, -1.7469, -3.1953, -2.3356]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.7896, -4.1682, -2.1145, -1.7685, -3.1762, -2.3033, -3.6228, -2.4834,\n",
      "         -2.9643, -1.7146, -3.0658, -2.2858],\n",
      "        [-2.7957, -4.3145, -2.3413, -1.8789, -3.2585, -2.2703, -3.4612, -2.4338,\n",
      "         -2.9576, -1.7455, -3.2240, -1.9007],\n",
      "        [-3.1158, -4.8968, -2.1110, -1.6183, -3.2082, -2.1969, -3.6604, -2.6760,\n",
      "         -3.1951, -1.6715, -3.5114, -2.0882],\n",
      "        [-2.7449, -3.6629, -2.0253, -1.7572, -2.8718, -2.2900, -3.3158, -2.5107,\n",
      "         -2.7719, -2.0728, -2.8978, -2.4453],\n",
      "        [-2.6815, -3.4670, -2.0392, -1.8514, -2.8094, -2.3843, -3.1714, -2.5520,\n",
      "         -2.7533, -2.0543, -2.9543, -2.3342],\n",
      "        [-2.6208, -3.6562, -2.0699, -1.7704, -2.8357, -2.3646, -3.2551, -2.4886,\n",
      "         -2.9233, -1.9797, -2.9988, -2.4195],\n",
      "        [-2.4798, -3.3190, -2.1160, -1.9054, -2.6876, -2.3881, -3.0586, -2.4650,\n",
      "         -2.7501, -2.2533, -2.8125, -2.4085],\n",
      "        [-2.5992, -3.4844, -2.0140, -1.8322, -2.7873, -2.3761, -3.1367, -2.4961,\n",
      "         -2.7802, -2.1545, -2.8829, -2.4396],\n",
      "        [-3.0526, -5.2412, -2.2756, -1.6640, -3.5925, -2.0125, -4.2693, -2.7504,\n",
      "         -3.5027, -1.3057, -3.5572, -2.4456],\n",
      "        [-3.1143, -5.6051, -2.4641, -1.9634, -4.2602, -2.2995, -4.3533, -2.4359,\n",
      "         -3.9859, -1.1018, -3.8491, -1.9698]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [00:01<00:01, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-14.5389, -34.0313, -10.0790,  -9.6197, -21.2236,  -4.3655, -25.3395,\n",
      "          -7.4880, -17.4130,  -0.2523, -18.7266,  -1.5625],\n",
      "        [ -2.5998,  -3.5321,  -2.1630,  -1.9150,  -2.8530,  -2.2050,  -3.1559,\n",
      "          -2.4523,  -2.7918,  -2.0603,  -2.8823,  -2.3773],\n",
      "        [ -3.5748,  -6.4196,  -2.7670,  -1.9511,  -4.3971,  -1.8177,  -4.9130,\n",
      "          -3.0457,  -3.7610,  -0.8525,  -4.2351,  -2.6357],\n",
      "        [ -2.9635,  -5.1749,  -2.3461,  -1.9179,  -3.6967,  -2.1321,  -4.0304,\n",
      "          -2.4543,  -3.4661,  -1.3248,  -3.3476,  -2.1144],\n",
      "        [ -3.0477,  -5.4281,  -2.3157,  -1.9604,  -3.8218,  -2.1696,  -4.0074,\n",
      "          -2.4868,  -3.4557,  -1.2265,  -3.6183,  -2.1249],\n",
      "        [ -2.8972,  -4.3929,  -2.3042,  -1.8620,  -3.1844,  -2.0112,  -3.5512,\n",
      "          -2.5626,  -2.9218,  -1.7297,  -3.1977,  -2.0857],\n",
      "        [ -2.5720,  -3.4010,  -1.9915,  -1.8752,  -2.8084,  -2.3248,  -3.0791,\n",
      "          -2.5284,  -2.8910,  -2.1329,  -2.8164,  -2.4923],\n",
      "        [ -2.5805,  -3.5985,  -2.1321,  -1.8487,  -2.8351,  -2.2377,  -3.2388,\n",
      "          -2.4365,  -2.8091,  -2.1175,  -2.8833,  -2.3834],\n",
      "        [ -2.5856,  -3.4875,  -2.1645,  -1.8932,  -2.8584,  -2.3608,  -3.1620,\n",
      "          -2.4685,  -2.7685,  -1.9389,  -2.9069,  -2.4230],\n",
      "        [ -2.6694,  -3.6322,  -2.1782,  -1.8830,  -2.8049,  -2.2784,  -3.2254,\n",
      "          -2.5239,  -2.8473,  -1.9020,  -2.9064,  -2.3636]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6566, -3.6722, -2.1052, -1.7127, -2.9460, -2.3307, -3.3593, -2.4532,\n",
      "         -2.8235, -2.0182, -2.9575, -2.4372],\n",
      "        [-2.6167, -3.7138, -2.1054, -1.7560, -2.7932, -2.3420, -3.3804, -2.5122,\n",
      "         -2.7385, -2.0751, -2.9639, -2.3674],\n",
      "        [-2.7816, -4.3512, -2.3336, -1.9558, -3.2036, -2.1458, -3.6162, -2.5064,\n",
      "         -2.8703, -1.4911, -3.2337, -2.3074],\n",
      "        [-2.6199, -3.3546, -2.1050, -1.8998, -2.7839, -2.3803, -3.1102, -2.3782,\n",
      "         -2.7325, -2.1514, -2.8263, -2.4239],\n",
      "        [-2.8463, -4.6378, -2.3737, -1.7940, -3.5682, -2.2721, -3.9913, -2.4290,\n",
      "         -3.2112, -1.3645, -3.2240, -2.3095],\n",
      "        [-2.6456, -3.8324, -2.2035, -1.8125, -2.8952, -2.2879, -3.2495, -2.3803,\n",
      "         -2.8355, -1.9887, -2.9000, -2.3536],\n",
      "        [-2.5463, -3.5197, -2.0960, -1.8537, -2.8227, -2.3799, -3.1953, -2.3880,\n",
      "         -2.7997, -2.0628, -2.8931, -2.4732],\n",
      "        [-3.1358, -5.0456, -2.6200, -2.0480, -3.3619, -1.6354, -3.6535, -2.8318,\n",
      "         -3.0845, -1.4596, -3.3040, -2.1275],\n",
      "        [-3.3497, -6.2673, -2.7656, -2.0189, -4.3895, -1.8507, -4.8276, -2.4889,\n",
      "         -3.5946, -1.0682, -3.5403, -2.2385],\n",
      "        [-2.5896, -3.5676, -2.2202, -1.8556, -2.8728, -2.3243, -3.1333, -2.4297,\n",
      "         -2.8994, -1.9487, -2.8760, -2.3873]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.5571, -3.5361, -2.1132, -1.9062, -2.7834, -2.3511, -3.2156, -2.3888,\n",
      "         -2.7567, -2.1040, -2.8288, -2.4042],\n",
      "        [-2.5691, -3.8070, -2.0888, -1.8040, -2.9732, -2.2603, -3.3276, -2.5050,\n",
      "         -2.8618, -1.9956, -2.9434, -2.3655],\n",
      "        [-2.6640, -4.3939, -2.2366, -1.9166, -3.2242, -2.2156, -3.6314, -2.3347,\n",
      "         -3.0451, -1.7877, -2.9628, -2.0775],\n",
      "        [-3.1545, -6.0048, -2.6641, -1.8847, -4.2363, -2.1506, -4.6037, -2.3353,\n",
      "         -3.8084, -0.9784, -3.6901, -2.6231],\n",
      "        [-2.4667, -3.4446, -2.1201, -1.9288, -2.7783, -2.3548, -3.1994, -2.3821,\n",
      "         -2.6991, -2.1376, -2.8513, -2.4686],\n",
      "        [-2.6961, -3.8924, -2.1309, -1.8516, -2.8669, -2.2704, -3.5157, -2.4197,\n",
      "         -2.7844, -1.9320, -2.9545, -2.3141],\n",
      "        [-3.9362, -7.2233, -2.9881, -2.3563, -4.4252, -1.1651, -5.0521, -2.7808,\n",
      "         -3.9005, -1.4340, -4.3935, -1.7637],\n",
      "        [-2.6880, -3.7420, -2.1761, -1.9175, -2.9308, -2.2940, -3.1959, -2.3701,\n",
      "         -2.9108, -1.8944, -2.8357, -2.3468],\n",
      "        [-2.9200, -5.1225, -2.3634, -1.9644, -3.6006, -2.2875, -3.9734, -2.2739,\n",
      "         -3.3730, -1.3938, -3.2621, -2.0063],\n",
      "        [-2.7772, -4.7219, -2.4862, -1.9751, -3.3279, -2.0524, -3.8359, -2.3836,\n",
      "         -2.9458, -1.4462, -3.1568, -2.3201]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6509, -3.8059, -2.0412, -1.8815, -2.8946, -2.2750, -3.2189, -2.3819,\n",
      "         -2.9737, -1.9687, -2.9327, -2.4032],\n",
      "        [-2.5336, -3.6858, -2.0868, -1.7623, -2.8338, -2.3844, -3.2700, -2.4187,\n",
      "         -2.8679, -2.1389, -2.9134, -2.3759],\n",
      "        [-2.9365, -5.4093, -2.7406, -1.9649, -3.8749, -1.7104, -4.2022, -2.3042,\n",
      "         -3.0494, -1.5001, -3.3857, -2.1450],\n",
      "        [-2.6459, -3.7309, -2.0105, -1.8226, -2.8878, -2.4241, -3.2875, -2.4290,\n",
      "         -2.8848, -1.9791, -2.9151, -2.3908],\n",
      "        [-2.4819, -3.4732, -2.1560, -1.8574, -2.7396, -2.3498, -3.1882, -2.3889,\n",
      "         -2.7112, -2.1825, -2.8626, -2.4741],\n",
      "        [-2.7322, -4.3276, -2.1843, -1.8658, -3.1482, -2.2807, -3.5014, -2.2132,\n",
      "         -3.0121, -1.8653, -3.0071, -2.1518],\n",
      "        [-2.6194, -3.5296, -2.0777, -1.8054, -2.8324, -2.4025, -3.2938, -2.4132,\n",
      "         -2.7971, -2.0451, -2.8271, -2.4930],\n",
      "        [-2.5730, -3.6017, -2.0809, -1.8636, -2.8170, -2.2784, -3.1708, -2.3972,\n",
      "         -2.7963, -2.1465, -2.8055, -2.4903],\n",
      "        [-3.0276, -6.0996, -2.6596, -2.1507, -4.1683, -1.8842, -4.3757, -2.0829,\n",
      "         -3.2859, -1.2643, -3.4942, -2.2242],\n",
      "        [-2.6337, -3.7817, -2.1376, -1.7694, -2.8284, -2.3825, -3.3432, -2.4105,\n",
      "         -2.8603, -2.0015, -2.8056, -2.4343]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-2.6259, -3.5353, -2.0676, -1.8084, -2.8278, -2.4005, -3.3195, -2.3678,\n",
      "         -2.7888, -2.1298, -2.7936, -2.4436],\n",
      "        [-2.6317, -3.7916, -2.0635, -1.7895, -3.0077, -2.3926, -3.3261, -2.3784,\n",
      "         -2.8718, -2.0181, -2.9232, -2.3152],\n",
      "        [-2.6064, -3.6871, -1.9582, -1.8414, -2.8187, -2.2694, -3.3542, -2.4285,\n",
      "         -2.7627, -2.1791, -2.9317, -2.4569],\n",
      "        [-2.6805, -4.0201, -2.1371, -1.9591, -3.0170, -2.1882, -3.3511, -2.3349,\n",
      "         -2.8586, -1.8471, -2.9239, -2.3769],\n",
      "        [-2.6375, -3.9003, -2.0218, -1.8421, -2.8797, -2.3408, -3.3703, -2.4157,\n",
      "         -2.8356, -2.0244, -2.8926, -2.3534],\n",
      "        [-2.6441, -3.6263, -2.0719, -1.8172, -2.8458, -2.3700, -3.3174, -2.3314,\n",
      "         -2.7486, -2.1475, -2.7952, -2.4417],\n",
      "        [-3.0032, -5.4085, -2.6505, -2.2449, -3.6434, -1.4969, -4.4071, -2.1418,\n",
      "         -2.9976, -1.6253, -3.2800, -2.2504],\n",
      "        [-4.1358, -8.5437, -3.1764, -2.7763, -5.7229, -1.8156, -6.6266, -2.4328,\n",
      "         -4.6578, -0.5877, -4.2166, -3.1044],\n",
      "        [-2.5765, -3.7353, -2.0207, -1.8849, -2.8829, -2.3101, -3.2701, -2.4273,\n",
      "         -2.8283, -2.0340, -2.8305, -2.4619],\n",
      "        [-2.5765, -3.9133, -2.1334, -1.7609, -2.9458, -2.3278, -3.4280, -2.3777,\n",
      "         -2.7951, -2.0093, -2.9606, -2.3925]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[-3.1363, -6.2647, -2.6224, -2.2788, -4.0451, -1.9682, -4.9789, -2.1171,\n",
      "         -3.4645, -0.9777, -3.5697, -2.8215],\n",
      "        [-3.1852, -5.3764, -2.5530, -2.2687, -3.5291, -1.4973, -3.8700, -2.3435,\n",
      "         -2.8380, -1.5911, -3.2023, -2.3039],\n",
      "        [-3.1810, -7.2993, -2.9742, -2.4153, -4.8517, -2.1045, -5.6818, -1.7729,\n",
      "         -3.8358, -1.1260, -3.2214, -2.0513],\n",
      "        [-4.2150, -7.9520, -3.3339, -2.9906, -5.0240, -0.7625, -5.0864, -2.5515,\n",
      "         -3.6201, -1.5249, -4.0994, -2.5166],\n",
      "        [-2.6342, -3.7577, -1.9272, -1.7922, -2.8685, -2.3705, -3.3421, -2.3568,\n",
      "         -2.8398, -2.1350, -2.8884, -2.5246],\n",
      "        [-2.6870, -3.7139, -2.0254, -1.7339, -2.8598, -2.3452, -3.3446, -2.4185,\n",
      "         -2.8438, -2.1096, -2.8078, -2.5043],\n",
      "        [-2.6916, -3.7462, -1.9884, -1.7375, -2.8928, -2.3564, -3.2927, -2.3879,\n",
      "         -2.8838, -2.1050, -2.8888, -2.4868],\n",
      "        [-2.6174, -3.6419, -2.0555, -1.8309, -2.8589, -2.3340, -3.3185, -2.4328,\n",
      "         -2.7082, -2.1214, -2.8292, -2.4227],\n",
      "        [-2.9906, -6.6113, -2.5083, -2.2944, -4.6202, -2.1316, -5.2461, -1.5740,\n",
      "         -3.6124, -1.2799, -3.2086, -2.5293],\n",
      "        [-2.6219, -3.7059, -2.0581, -1.7157, -2.8264, -2.3747, -3.4071, -2.3836,\n",
      "         -2.8025, -2.0939, -2.9116, -2.5338]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [00:01<00:00, 16.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ee5b619f0836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mIyer_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIyer_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRITERION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-187dfafe7e00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Iyer_net = CNN(12, 1, 12)\n",
    "optimizer = optim.Adam(Iyer_net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "for batch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, training_set_size, BATCH_SIZE)):\n",
    "        batch_X = train_X[i:i+BATCH_SIZE]\n",
    "        batch_y = train_y[i:i + BATCH_SIZE]\n",
    "        \n",
    "        Iyer_net.zero_grad()\n",
    "        output = Iyer_net(batch_X)\n",
    "        print(output)\n",
    "        loss = CRITERION(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(105)\n",
      "tensor(45)\n",
      "tensor(45)\n",
      "tensor(41)\n",
      "tensor(9)\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3831f9ad8957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mIyer_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 0]"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "true = []\n",
    "Iyer_net.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, validation_X.shape[0], BATCH_SIZE):\n",
    "        print(torch.argmax(Iyer_net(validation_X[i:i+BATCH_SIZE])).cpu())\n",
    "        true.append(validation_y[i:i:BATCH_SIZE])\n",
    "Iyer_net.train()\n",
    "print(output)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(true, output))\n",
    "print(\"Validation F1 Score:\", metrics.f1_score(true, output, average=\"macro\"))\n",
    "true = np.eye(10)[true]\n",
    "output = np.eye(10)[output]\n",
    "print(\"Validation AUC Score:\", metrics.roc_auc_score(true, output, multi_class=\"ovo\", average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
